[topic thowto same "BIF/Thread" "BIF/Thread - howto" secondary]
This section show solutions to problems you may encounter in
multithreaded programs. Most of the problems are how to communicate
between threads.

Select a topic:
[sl]
[li][ref thowto_shared_variables "Protecting shared variables"]
[li][ref thowto_callback "An 'external-wait-thing' under Windows 3.1"]
[li][ref thowto_boundedbuffer "The 'bounded buffer' problem"]
[li][ref thowto_readersandwriters "The 'readers and writers' problem"]
[li][ref thowto_backgroundpainting "Painting a window in the background"]
[li][ref thowto_backgroundfeedback "Background job status feedback"]
[li][ref thowto_spin "Spinning semaphore and when and how to use them"]
[esl]
[etopic]



[topic thowto_shared_variables down "Protecting shared variables"]
This topic shows how to ensure that only one thread at a time accesses
a structure shared between two or more threads.

The following solution is utterly simple: use a mutex semaphore to ensure
exclusive access.
[code]
Stack mystack;
[ref FMutexSemaphore "FMutexSemaphore"] mystack_lock;


thread 1:
  ...
  protect_mystack.Request();
  <access mystack>
  protect_mystack.Release();

thread 2:
  protect_mystack.Request();
  <access mystack>
  protect_mystack.Release();
[ecode]


While the use a separate mutex is non-intrusive to the stack the
explicit use of the mutex is error-prone. A usually better
solution is to put the synchronization into the structure itself or
create a wrapper class that implements the synchronization.
[code]
class SynchronizedStack : public Stack {
  [ref FMutexSemaphore "FMutexSemaphore"] mutex;
public:
  void push(int e);
  int pop();
  int top();
  int isEmpty();
}

void SynchronizedStack::push(int e) {
  mutex.Request();
  Stack::push(e);
  mutex.Release();
}

int SynchronizedStack::pop() {
  mutex.Request();
  int e=Stack::pop(e);
  mutex.Release();
  return e;
}
int SynchronizedStack::top() {
  mutex.Request();
  int e=Stack::top(e);
  mutex.Release();
}
int SynchronizedStack::isEmpty() {
  mutex.Request();
  int is=Stack::isEmpty(e);
  mutex.Release();
  return is;
}
[ecode]

The use of a FMutexSemaphore does not scale well. If several threads
accesses the shared structure and they spend most of the time waiting
for the mutex to be released an other approach is needed. The access
to the shared structure can be replaced by message-passing or the
structure can be synchornized like the
[ref thowto_boundedbuffer "'bounded buffer problem'"]
[etopic]


[topic thowto_callback same "An 'external-wait-thing' under Windows 3.1" "An 'external-wait-thing' uner Windows 3.1" only]
This topic shows how make an interface to external sources with
BIF/Thread under Windows 3.1. The solution apply to most APIs where
callbacks or notifications can be used, eg, the communication interface 
under Windows, the IPX interface and sockets.

The problem is: to create a interface class to an external library, so the
class provide blocking operations while the application can remain
responsive to the user interface.


The solution is to have a FEventSemaphore in the wrapper class. When the
event is detected (either in a callback function or through a notification
message) the event semaphore is posted.

The following code fragment implements wrapper class for an unspecified API.
Read and write semantics are assumed.
[code]
class MyWaitThing {
  FEventSemaphore dataReady;
  FEventSemaphore dataSent;
  void *readDataBuffer;
  void *writeDataBuffer;
  void readReturnValue;
  void writeReturnValue;
  friend void callbackFunction(...);
static MyWaitThing *theWaitThing;
public:
  int read(void *buf);
  int write(void *buf);
};

MyWaitThing  MyWaitThing::theWaitThing=0;

int MyWaitThing::read(void *buf) {
  dataReady.Reset();
  readDataBuffer=buf;
  API::SetCallback(callbackFunction);
  API::<start reading>
  dataReady.Wait();
  return readReturnValue;
}

int MyWaitThing::write(void *buf) {
  dataSent.Reset();
  writeDataBuffer=buf;
  API::SetCallback(callbackFunction);
  API::<start writing>
  dataSent.Wait();
  return writeReturnValue;
}


void callbackFunction(...) {
  //determine what happened
  theWaitThing->readReturnValue = ...;
  theWaitThing->dataReady.Post();
}


//Using the wrapper class
MyWaitThing device;

MyThread::Go() {
  //this thread reads from the device and puts it into a file
  FILE *fp=fopen("data.in","wb");
  while(<continue>) {
    char buffer\[1024\];
    device.read(buffer);
    fwrite(buffer,1024,1,fp);
  }
}
[ecode]

The above callback function is not necessarily a callback function. It could
have been the messageloop detecting a WM_COMMNOTIFY message.
[etopic]


[topic thowto_boundedbuffer same "The 'bounded buffer' problem"]
This topic shows a solution to the "bounded buffer problem" using BIF/Thread.
Many solution exist - this is just one. The 'bounded buffer' problem is often
met in multithreaded programs. It is when two thread communicate with each
other through a buffer of limited size. One thread produces data (eg. reads from a disk)
while another thread processes it. To enhance performance a buffer is inserted
between the two threads so they do not have to run at the same speed.
[code]
producer -> \[buffer\] -> consumer
[ecode]

The solution is the normal solution when semaphores are available:
[code]
#define maxbuf 10
struct Element {
  ...
};

class Buffer {
  Element buffer\[maxbuf\];
  int head,tail;
  FSemaphore notfull,notempty;
public:
  Buffer();
  void Get(Element &e);
  void Put(const Element &e);
};

Buffer::Buffer()
  : head(0),tail(0),
    notfull(maxbuf), notempty(0)
{ }

void Buffer::Get(Element &e) {
  //retrieve an element from the buffer
  
  //wait until there is an element
  notempty.Wait();
  //take it
  e = buffer\[head\];
  head = (head+1)%maxbuf;
  //since we have taken an element there is room for one more.
  notempty.Signal();
}

void Buffer::Put(const Element &e) {
  //append an element to the buffer
  
  //wait until there is room for it
  notfull.Wait();
  //append the element
  buffer\[tail\] = e;
  tail = (tail+1)%maxbuf;
  //tell that there is one more element
  notempty.Signal();
}
[ecode]

The buffer is a circular buffer. When the producer thread inserts an item
it has to wait until there is room for it (the consumer may be slow),
insert it and then tell the consumer thread that there is one more element
in the buffer. When the consumer thread wants to take an element it must
wait until there is one (the producer may be slow), take it and then tell the
producer thread that there is room for one more element.

This fragment shows how to use the buffer. The code fragment contains the
framework of a decompression program. The decompression program uses three threads:
[ul]
[li]A disk-read thread that reads blocks from a disk.
[li]A decompression thread that decompresses the blocks that the disk-read thread has put into a buffer
[li]A disk-write thread that writes the decompressed blocks to the disk.
[eul]

[code]
//blocks of 1024 byts are used
struct Element {
  char b\[1024\];
  int size;         //size of block. non-1024 only in last block
};

Buffer compressedBlocks;   //buffer between reader and decompressor
Buffer decompressedBlocks; //buffer between decompressor and writer
FILE *fpInput,*fpOutput;   //input and output files

class ReaderThread : public FThread {
public:
  void Go();
};

class DecompressorThread : public FThread {
public:
  void Go();
};

class WriteThread : public FThread {
public:
  void Go();
};


void ReaderThread::Go() {
  Element e;
  int bytesRead;
  
  do {
    bytesRead = fread(e.b, 1, 1024, fpInput);
    if(bytesRead>0) {
      e.size = bytesRead;
      compressedBlocks.Put(e);
    }
  } while(bytesRead>0);
}

void DecompressorThread::Go() {
  <various state variables for the decompression>
  Element in;
  Element out;
  
  do {
    decompressedBlocks.Get(e);
    if(e.size!=0) {
      //decompress block
      for (...)
        ...
        if(out.size==1024) {
          //output block is full
          decompressedBlocks.Put(out);
          out.size=0;
        }
        ...
    }
  } while(in.size==1024);
  //flush last block
  if(out.size>0) {
    decompressedBlocks.Put(out);
  }
}


void WriterThread::Go() {
  Element e;
  do {
    decompressedBlocks.Get(e);
    if(e.size>0)
      fwrite(e.b, 1, e.size, fpOutput);
  } while(e.size==1024);
}
[ecode]

A nice sideeffect of the code fragment above is that it saves time (except
under Windows 3.1). Instead of the running time being read-time +
decompression-time + write-time it is max(read-time,decompression-time,write-time). 
Assume the input file is on a diskette and the output file is on a harddisk. 
Reading 1.44MB from a diskette takes 60 seconds minute, decrompressing 1 MB 
takes 20 seconds and writing the decompressed file (approx 3MB) takes 5 
seconds. The running time of a single-threaded decompressor would take:
[code]
  60 + 20 + 5  = 85 seconds
[ecode]
However, the running time of the multi-threaded decompressor in the code
fragment above would take:
[code]
  max(60,20,5) = 60 seconds
[ecode]
[etopic]


[topic thowto_readersandwriters same "The 'readers and writers' problem"]
The 'readers and writers' problem is also often met in multithreaded programs.
It is when a shared structure is accesses by many threads. The structure can
handle that multiple threads read the structure but only one thread at a time
may modify it (and then there must be no readers).

The problem can be solved with a single mutex but this is often not
satisfactory since is limits the number of threads simultaneously accessing
the structure to 1.

The goal is to create a synchronization mechanism that:
[ul]
[li]Allows multple threads to read the structure
[li]Allows one thread to modify the structure
[li]Ensures that the structure is not modified when there are threads reading the structure
[eul]

In addition to this the structure must also be free of deadlocks and livelocks:
[ul]
[li]A writer must wait until there are no readers accessing the structure
[li]When a writer is waiting no readers are allowed to begin reading the structure
[li]A reader is always allowed to stop reading the structure
[eul]

And just because we are masochistic :-) we also want it to work in a SMP environment.

The mechanism has four operations:
[sl]
[li]Start writing
[li]Finish writing
[li]Start reading
[li]Finish reading
[esl]

The following code fragment is a bit tricky.
[code]
class RW {
  FMutexSemaphore modify;               //mutex for writing (and blocking readers)
  FEventSemaphore noReaders;            //posted when there are no readers
  int readers;                          //#readers
  FMutexSemaphore countModify;          //protects above member
public:
  RW();
  
  void WriteLock();
  void WriteUnlock();
  
  void ReadLock();
  void ReadUnlock();
};

RW::RW()
{
  noReaders.Post();
  readers=0;
}

void RW::WriteLock() {
  modify.Request();                     //ensure only one writer
  noReaders.Wait();                     //wait until all readers have left
}

void RW::WriteUnlock() {
  modify.Release();                     //not writing anymore
}

void RW:ReadLock() {
  modify.Request();                     //wait until no writers
    countModify.Request();              //only one reader at a time may modify the count
      if(readers==0) {
        noReaders.Reset();              //going from 0 to 1 readers
      readers++;
    countModify.Release();
  modify.Release();
}

void RW::ReadUnlock() {
  countModify.Request();                //only one reader at a time may modify the count
    readers--;
    if(readers==0)                      //last reader leaving
      noReaders.Post();
  countModify.Release();
}
[ecode]

The above mechanism is SMP-safe, free of livelocks and reasonably free of
deadlocks. A writer will deadlock itself if it has called ReadLock() and
then tries to make a WriteLock(). A writer is, however, allowed to first
call WriteLock() and then ReadLock() without deadlocking itself.

The following fragment show how to use it:
[code]
BinaryTree tree;
RW tree_RW;

void reader() {
  //traverse the tree
  tree_RW.ReadLock();
    traverse(tree.top());
  tree_RW.ReadUnlock();
}

void writer() {
  //insert an element in the tree
  tree_RW.WriteLock();
    tree.insert(...);
  tree_RW.WriteUnlock();
}
[ecode]
[etopic]



[topic thowto_backgroundpainting same "Painting a window in the background"]
This topic shows how you can paint a window in a background thread.

The purpose of painting a window in a background thread is that some windows
have very complex contents that take long time to paint. For instance a
window could contain graphics that involved heavy calculations to paint,
Bezier-curves combined with stretching, rotating and mapping 16M colors to a
dynamic 256 color palette.

If the calculation/retrieval of the data to present in the window takes long
time it is a completely other problem, more like
[ref thowto_backgroundfeedback "'Background job status feedback'"]

The general idea is to answer the WM_PAINT message immidiatly and letting
the background thread paint the window. The background painting thread is
keept around for several repaints.

The following code uses the Windows API, but OS/2 PM is essentially the same.
The code assumes that the Queue class is thread-aware (this could be done
like the [ref thowto_boundedbuffer "'bounded buffer' problem"])
[code]
Queue<RECT> paintQueue;
FEventSemaphore workToDo;
int stop=0;
HWND hwndPaint;

class BPThread : public FWindowThread {
public:
  void Go();
};

void BPThread::Go() {
  while(!stop) {
    workToDo.Wait();    //Go to sleep until there is something to paint
    workToDo.Reset();   //Ok, were are awake now.
    while(!stop && !paintQueue.IsEmpty()) {
      RECT rectPaint=paintQueue.Get();
      HDC hdcPaint = GetDC(hwndPaint);
      
      <paint the rectangle>
      ReleaseDC(hwndPaint,hdcPaint);
    }
  }
  PostMessage(hwndPaint, WM_PAINTHREAD_TERMINATED,0,0); //Ackowledge the termination request
}


LRESULT MyWindowProc(HWND hwnd, UINT msg, WPARAM wParam, LPARAM lParam) {
  switch(msg) {
    case WM_PAINT: {
      PAINTSTRUCT ps;
      BeginPaint(hwnd,&ps);
      paintQueue.Put(ps.rcPaint);       //put the rectangle into the paint queue
      EndPaint(hwnd,&ps);
      workToDo.Post();                  //wake the thread
      return 0;
    }
    case WM_CLOSE: {
      //We cannot just close the window. We must wait for the background
      //painting thread to terminate first.
      stop = 1;
      workToDo.Post();                  //wake the thread
      return 0;
    }
    case WM_PAINTHREAD_TERMINATED: {
      //the background painting thread has terminated
      DestroyWindow(hwnd);
      PostQuitMessage(0);
    }
    ...
  }
}
[ecode]
[etopic]


[topic thowto_backgroundfeedback same "Background job status feedback" "Background job status feedback" only]
This topic discusses various methods of giving the user progress information
on a task executed by a background thread.

Several subjects must be adressed:
[dl]
[dt]Immidiate feedback
[dd]The user should have immidiate feedback when he starts the task. If not,
he may not realize that the task is being carried out. The feedback can range
from a beep, changing the text in a status bar to displaying a window.
[dt]When to update progress information
[dd]While the task is being carried out the user should be able to track the
progress of the task. Eg. the number of pages printed, the state of the task or
displaying the results as they are computed.
[dt]How to signal status change
[dd]The method of communication from the background thread to the GUI thread.
[dt]Completion feedback
[dd]What to do when the task has finished
[dt]How to stop the job
[dd]Since we are building user-friendly programs :-), the user should be able
to stop the task.
[edl]

[graphic bitmap "Communication between the two threads" "winbmp:thowto_1.bmp" "os2bmp:thowto_1.bmp"]

The following code fragment shows how your can implement background printing.
[code]
class PrintThread : public FWindowThread {
  HWND hwndNotify;
public:
  PrintThread(HWND hwnd, ...);
  void Go();

  int noOfPages:
  int currentPage;
  int stop;
};

void PrintThread::Go() {
  <prepare printing>
  for(currentPage=0; currentPage<noOfPages; currentPage++) {
    //tell the progress window to update information
    WinPostMsg(hwndNotify, WM_UPDATEPRINTPROGRESS, 0,0);
    //Ensure that we don't eat all the time
    Yield();

    <print the page>
    if(stop) break;

  }
  <end printing>
  WinPostMsg(hwndNotify, WM_PRINTFINISHED, 0,0);
}

PrintThread *printThread;
MRESULT PrintProgressWndProc(HWND hwmd, MSG msg, MPARAM mp1, MPARAM mp2) {
  //window procedure for the
  switch(msg) {
    case WM_INITDLG:
      printThread = new PrintThread(hwnd, ...);
      return FALSE;

    case WM_COMMAND:
      if(SHORT1FROMMP(mp1)==DID_CANCEL) {
        //abort printing
        printThread->stop = 1;
      }
      return 0;

    case WM_UPDATEPRINTPROGRESS:
      //The thread thinks it a good time to update the progress information
      //we just update the number of pages printed
      WinSetDlgItemShort(hwnd, DID_PRINITINGPAGE, printThread->currentPage, FALSE);
      return 0;

    case WM_PRINTFINISHED:
      //the thread has finished printing
      printThread->Wait();  //wait for the thread to terminate (it probably already has)
      delete printThread;
      WinDismissDlg(hwnd,0);
      return 0;
  }
  return DefDlgProc(hwnd,msg,mp1,mp2);
}

MRESULT MainWndProc(HWND hwnd, MSG msg, MPARAM mp1, MPARAM mp2) {
  //window procedure for the main window
  switch(msg) {
    case WM_COMMAND:
      switch(SHORT1FROMMP(mp1)) {
        case CID_PRINT:
          WinDlgBox(HWND_DESKTOP,hwnd,PrintProgressWndProc,NULL,IDD_PRINTPROGRESS,NULL);
        case ...
      }
      return 0;
    ...
  }
  return WinDefWindowProc(hwnd,msg,mp1,mp2);
}

[ecode]
[etopic]

[topic thowto_spin upafter "Spinning Semaphores"]
BIF/Thread offers three spinning semaphores:
[ul]
[li][ref fspinmutexsemaphore "FSpinMutexSemaphore"]
[li][ref fspineventsemaphore "FSpinEventSemaphore"]
[li][ref fspinsemaphore "FSpinSemaphore"]
[eul]
These semaphore try to optimize out of expensive system call and thereby
reducing the overhead of the synchronization. In general they spin in a tight
loop waiting for the condition to occur (thus the name "spinning") and if that
doesn't work within a certain amount of time the revert to the operating
system's semaphores.

They have the following advantage over the standard semaphores:
[ul]
[li]They are faster.
[eul]

They have the following disadvantages:
[ul]
[li]They are partly or fully program-managed (not system managed). Because they use data
accessable to the program memory overwrites can have terribly consequences.
[li]When the condition they wait for is not true within a short period of time
and they revert to the standard semaphores they will have used more CPU
resources than the standard semaphores.
[li]In general, they cannot detect error conditions, such as when the owner of a
FSpinMutexSemaphores dies without releasing it, or when a FEventSemaphore's
destructor is called while threads are waiting for it. This can lead to deadlocks.
[li]They do not have timeouts.
[li]They cannot be used with the operating system functions
[eul]

[hp 2]When to use spinning semaphores[ehp]

If you expect threads to block on the semaphores' wait function in less than 5% of
the calls, that is:
[ul]
[li]FSpinEventSemaphore is usually posted.
[li]FSpinMutexSemaphore is requested for [hp 1]very[ehp] short periods of time
[li]Only 1-2 threads are using a FSpinMutexSemaphore object
[li]FSemaphore's count is usually above 0
[eul]
You should not use spinning semaphores unless you have verified that the
standard semaphores are responsible for more than 20% of your program's
running time.

[hp 2]When spinning semaphores should be avoided[ehp]
[ul]
[li]When more than, say, 5 threads are requesting a FSpinMutexSemaphore
[li]When FSpinEventSemaphore's count is around 0-1.
[li]When your program is not fully debugged
[li]When your have not tried something else, such as reducing the amount
of synchronization. For instance, instead of transferring small blocks of data
(eg. 1 byte) from one thread to another a a time, try transferring large chunks
of data (eg. 4K) instead.
[eul]
[etopic]

